from pathlib import Path
import json
import tempfile
from datetime import datetime

from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate


class MedicalInterviewBot:
    def __init__(self, rebuild_db: bool = False):
        self.script_dir = Path(__file__).parent
        self.data_dir = self.script_dir / "enhanced_dataset"

        temp_base = Path(tempfile.gettempdir())
        self.db_dir = temp_base / "medical_bot_db"

        self.conversation_history = []
        self.collected_info = {
            "chief_complaint": "",
            "symptoms": [],
            "duration": "",
            "additional_info": []
        }

        print("=" * 70)
        print("üè• –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ò–ù–¢–ï–†–í–¨–Æ–ï–† v3.0 (enhanced_dataset)")
        print("=" * 70)
        print(f"\nüìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db_dir}")

        if not self.data_dir.exists():
            print(f"\n‚ùå –ü–∞–ø–∫–∞ {self.data_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            exit(1)

        if rebuild_db and self.db_dir.exists():
            print("\nüóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
            import shutil
            shutil.rmtree(self.db_dir)
            print(" ‚úÖ –£–¥–∞–ª—ë–Ω")

        self._load_or_create_knowledge_base()

        print("\nü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        self.llm = ChatOllama(model="llama3.1", temperature=0.3)
        print(" ‚úÖ llama3.1 –≥–æ—Ç–æ–≤–∞")

        print("\n" + "=" * 70)
        print("‚úÖ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê!")
        print("=" * 70)

    # ---------- –†–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π ----------

    def _load_or_create_knowledge_base(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–¥ enhanced_dataset."""
        embeddings = OllamaEmbeddings(model="nomic-embed-text")

        if self.db_dir.exists() and (self.db_dir / "index.faiss").exists():
            print("\nüìö –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π FAISS –∏–Ω–¥–µ–∫—Å")
            print(f" –ü—É—Ç—å: {self.db_dir}")
            try:
                print(" ‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞...")
                self.vectorstore = FAISS.load_local(
                    str(self.db_dir),
                    embeddings,
                    allow_dangerous_deserialization=True,
                )
                _ = self.vectorstore.similarity_search("—Ç–µ—Å—Ç", k=1)
                print(" ‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return
            except Exception as e:
                print(f" ‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                print(" üîÑ –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å...")

        print("\nüìö –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ FAISS –∏–Ω–¥–µ–∫—Å–∞ (enhanced_dataset)")
        print(" ‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 5‚Äì15 –º–∏–Ω—É—Ç\n")
        self._create_new_database(embeddings)

    def _create_new_database(self, embeddings):
        """–°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ enhanced_dataset."""
        print("1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

        documents = []
        json_files = list(self.data_dir.glob("*.json"))

        if not json_files:
            print(" ‚ùå –í –ø–∞–ø–∫–µ enhanced_dataset –Ω–µ—Ç JSON‚Äë—Ñ–∞–π–ª–æ–≤!")
            exit(1)

        total = len(json_files)
        print(f" –ù–∞–π–¥–µ–Ω–æ: {total} —Ñ–∞–π–ª–æ–≤")

        for i, json_file in enumerate(json_files, 1):
            try:
                with open(json_file, "r", encoding="utf-8") as f:
                    data = json.load(f)

                title = (data.get("title") or "").strip()
                sections = data.get("sections", {})
                full_text = f"# {title}\n\n"

                for section_name, section_text in sections.items():
                    if not section_text or not str(section_text).strip():
                        continue
                    readable_name = section_name.replace("_", " ").title()
                    full_text += f"## {readable_name}\n{section_text}\n\n"

                if len(full_text) <= 100:
                    continue

                meta = data.get("metadata", {}) or {}
                doc_metadata = {
                    "title": title,
                    "disease": title,
                    "file": json_file.name,
                    "categories": meta.get("categories", []),
                    "symptoms": meta.get("symptoms", []),
                    "complexity": meta.get("complexity", ""),
                    "symptoms_count": meta.get("symptoms_count", 0),
                    "filled_sections": meta.get("filled_sections", 0),
                    "total_sections": meta.get("total_sections", 0),
                    "completeness_score": meta.get("completeness_score", 0.0),
                }

                documents.append(
                    Document(page_content=full_text, metadata=doc_metadata)
                )

                if i % 50 == 0 or i == total:
                    print(f" üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {i}/{total}")

            except Exception as e:
                print(f" ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ {json_file.name}: {e}")

        print(f" ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π: {len(documents)}")

        print("\n2Ô∏è‚É£ –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100,
        )
        splits = text_splitter.split_documents(documents)
        total_splits = len(splits)
        print(f" ‚úÖ –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {total_splits}")

        print("\n3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        print(" ‚è≥ –≠—Ç–æ –∑–∞–π–º—ë—Ç –≤—Ä–µ–º—è, –¥–æ–∂–¥–∏—Ç–µ—Å—å –æ–∫–æ–Ω—á–∞–Ω–∏—è\n")

        batch_size = 100
        vectorstore = None

        try:
            for i in range(0, total_splits, batch_size):
                batch = splits[i : i + batch_size]
                if vectorstore is None:
                    vectorstore = FAISS.from_documents(batch, embeddings)
                else:
                    vectorstore.add_documents(batch)

                progress = min(i + batch_size, total_splits)
                percent = (progress / total_splits) * 100
                print(f" üìä {progress}/{total_splits} ({percent:.1f}%)")

            self.vectorstore = vectorstore

            print("\n4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞...")
            self.db_dir.mkdir(parents=True, exist_ok=True)
            self.vectorstore.save_local(str(self.db_dir))
            print(f" ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {self.db_dir}")

        except Exception as e:
            print(f"\n ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _search_context(self, query: str, k: int = 3) -> str:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ FAISS."""
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            return "\n\n".join(doc.page_content[:700] for doc in docs)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return ""

    # ---------- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–≤–æ–¥–∞ ----------

    def _is_valid_medical_input(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞."""
        if not text or len(text.strip()) < 3:
            return False
        
        text_lower = text.lower()
        
        # –ß—ë—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ—Å—Å–º—ã—Å–ª–∏—Ü—ã
        bad_words = ["–Ω–µ —Å—Ç–æ–∏—Ç", "—Ö–∞ —Ö–∞", "–∫–µ–∫", "zzz", "123", "–Ω–µ–Ω—É–∂–Ω–æ"]
        if any(word in text_lower for word in bad_words):
            return False
        
        # –ú–∏–Ω–∏–º—É–º 2 —Å–ª–æ–≤–∞
        return len(text.split()) >= 2

    def _get_valid_patient_answer(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π."""
        attempts = 0
        max_attempts = 3
        
        while attempts < max_attempts:
            answer = input("üë§: ").strip()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
            if answer.lower() in ["exit", "–≤—ã—Ö–æ–¥"]:
                print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                return None
            if answer.lower() == "—Å—Ç–æ–ø":
                return "STOP"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
            if not self._is_valid_medical_input(answer):
                attempts += 1
                if attempts < max_attempts:
                    print(f"\n‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É. "
                          f"–ü–æ–ø—ã—Ç–∫–∞ {attempts}/{max_attempts}\n")
                    continue
                else:
                    print("\n‚ùå –ü–æ—Ö–æ–∂–µ, –≤—ã –Ω–µ —Ö–æ—Ç–∏—Ç–µ –æ–±—Å—É–∂–¥–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É.")
                    return None
            
            return answer
        
        return None

    # ---------- –õ–æ–≥–∏–∫–∞ –¥–∏–∞–ª–æ–≥–∞ ----------

    def _should_continue(self) -> bool:
        """–†–µ—à–µ–Ω–∏–µ, –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é."""
        questions = len(
            [m for m in self.conversation_history if m["role"] == "assistant"]
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        has_chief_complaint = bool(self.collected_info["chief_complaint"])
        has_symptoms = len(self.collected_info["symptoms"]) >= 3
        has_duration = bool(self.collected_info["duration"])
        
        has_enough_info = has_chief_complaint and has_symptoms and has_duration
        
        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"\nüìä –°—Ç–∞—Ç—É—Å: –≤–æ–ø—Ä–æ—Å–æ–≤={questions}, —Å–∏–º–ø—Ç–æ–º–æ–≤={len(self.collected_info['symptoms'])}, "
              f"–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å={'‚úì' if has_duration else '‚úó'}")
        
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–ª–∏ 15 –≤–æ–ø—Ä–æ—Å–æ–≤ –ò –Ω–µ —Å–æ–±—Ä–∞–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        return questions < 15 and not has_enough_info

    def _generate_question(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –≤—Ä–∞—á—É-–±–æ—Ç–æ–º."""
        search_query = f"{self.collected_info['chief_complaint']} " \
                       f"{' '.join(self.collected_info['symptoms'])}"
        context = self._search_context(search_query, k=2)

        history = "\n".join(
            f"{'–í—Ä–∞—á' if m['role'] == 'assistant' else '–ü–∞—Ü–∏–µ–Ω—Ç'}: {m['content']}"
            for m in self.conversation_history[-4:]
        )

        prompt = ChatPromptTemplate.from_template(
            """
–¢—ã –≤—Ä–∞—á, —Å–æ–±–∏—Ä–∞—é—â–∏–π –∞–Ω–∞–º–Ω–µ–∑. –ï—Å–ª–∏ –ø–∞—Ü–∏–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª –Ω–µ–≤—Ä–∞–∑—É–º–∏—Ç–µ–ª—å–Ω–æ, 
—Ç–∞–∫—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –ø—Ä–æ–±–ª–µ–º—É.

–ò–°–¢–û–†–ò–Ø:
{history}

–ò–ù–§–û–†–ú–ê–¶–ò–Ø:
- –ñ–∞–ª–æ–±–∞: {chief_complaint}
- –°–∏–º–ø—Ç–æ–º—ã: {symptoms}

–ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
{context}

–ó–∞–¥–∞–π –û–î–ò–ù –∫–æ—Ä–æ—Ç–∫–∏–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ –¥–µ–ª—É:"""
        )

        try:
            from langchain_core.runnables import RunnableConfig

            response = self.llm.invoke(
                prompt.format(
                    history=history,
                    chief_complaint=self.collected_info["chief_complaint"] or "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                    symptoms=", ".join(self.collected_info["symptoms"]) if self.collected_info["symptoms"] else "–Ω–µ—Ç",
                    context=context or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                ),
                config=RunnableConfig(max_concurrency=1, timeout=60),
            )
            return response.content.strip()
        except Exception as e:
            print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM: {e}")
            fallback_questions = [
                "–ö–∞–∫ –¥–∞–≤–Ω–æ —É –≤–∞—Å —ç—Ç–∏ —Å–∏–º–ø—Ç–æ–º—ã?",
                "–£—Å–∏–ª–∏–≤–∞—é—Ç—Å—è –ª–∏ —Å–∏–º–ø—Ç–æ–º—ã –ø–æ—Å–ª–µ –µ–¥—ã –∏–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏?",
                "–ï—Å—Ç—å –ª–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞?",
                "–ì–¥–µ –∏–º–µ–Ω–Ω–æ –ª–æ–∫–∞–ª–∏–∑—É–µ—Ç—Å—è –±–æ–ª—å?",
                "–ï—Å—Ç—å –ª–∏ —Ç–æ—à–Ω–æ—Ç–∞ –∏–ª–∏ —Ä–≤–æ—Ç–∞?",
            ]
            import random
            return random.choice(fallback_questions)

    def _extract_info(self, text: str):
        """–ì—Ä—É–±–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–º–ø—Ç–æ–º–æ–≤ –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞."""
        text_lower = text.lower()

        time_words = ["–¥–µ–Ω—å", "–¥–Ω—è", "–¥–Ω–µ–π", "–Ω–µ–¥–µ–ª—é", "–º–µ—Å—è—Ü", "–≥–æ–¥", "—á–∞—Å", "—á–∞—Å–æ–≤", "–º–∏–Ω—É—Ç"]
        if any(w in text_lower for w in time_words) and not self.collected_info["duration"]:
            self.collected_info["duration"] = text

        symptoms_vocab = [
            "–±–æ–ª—å", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "—Ç–æ—à–Ω–æ—Ç–∞", "—Ä–≤–æ—Ç–∞", "—Å–ª–∞–±–æ—Å—Ç—å", 
            "–∫–∞—à–µ–ª—å", "–Ω–∞—Å–º–æ—Ä–∫", "–≥–æ—Ä–ª–æ", "–≥–æ–ª–æ–≤–∞", "–∂–∏–≤–æ—Ç", 
            "—Å—ã–ø—å", "–æ–∑–Ω–æ–±", "–≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏–µ", "–¥–∏–∞—Ä–µ—è", "–∑–∞–ø–æ—Ä"
        ]
        
        for symptom in symptoms_vocab:
            if symptom in text_lower:
                if symptom not in " ".join(self.collected_info["symptoms"]).lower():
                    self.collected_info["symptoms"].append(symptom)

    def _generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π."""
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∂–∞–ª–æ–±—ã
        if not self.collected_info["chief_complaint"]:
            return """‚ùå –û–®–ò–ë–ö–ê: –û—Å–Ω–æ–≤–Ω–∞—è –∂–∞–ª–æ–±–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞ –Ω–µ –±—ã–ª–∞ —Å–æ–±—Ä–∞–Ω–∞.
        
–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á—ë—Ç –±–µ–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–±–ª–µ–º–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞.
–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤—å—é."""
        
        # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        clean_history = []
        for msg in self.conversation_history:
            content = msg.get("content", "").strip().lower()
            
            if any(bad in content for bad in [
                "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å",
                "–Ω–µ—É–º–µ—Å—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å",
                "–Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π",
                "–Ω–µ —Å—Ç–æ–∏—Ç",
                "—Ö–∞ —Ö–∞",
                "–∫–µ–∫"
            ]):
                continue
            
            clean_history.append(msg)
        
        if len(clean_history) < 3:
            clean_history = self.conversation_history
        
        conversation = "\n".join([
            f"{'–í—Ä–∞—á' if m['role'] == 'assistant' else '–ü–∞—Ü–∏–µ–Ω—Ç'}: {m['content']}"
            for m in clean_history
        ])
        
        search_query = " ".join([
            self.collected_info["chief_complaint"],
            *self.collected_info["symptoms"]
        ])
        context = self._search_context(search_query, k=5)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤
        symptoms_list = [s for s in self.collected_info["symptoms"] if len(s) > 2]
        if not symptoms_list:
            symptoms_list = ["–Ω–µ —É—Ç–æ—á–Ω–µ–Ω—ã"]
        
        prompt = ChatPromptTemplate.from_template("""
–¢—ã –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á, –≥–æ—Ç–æ–≤—è—â–∏–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–º–Ω–µ–∑ –ø–∞—Ü–∏–µ–Ω—Ç–∞ –¥–ª—è –∫–æ–ª–ª–µ–≥.
–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ª–æ–≥–∞ –Ω–∏–∂–µ, –∑–∞–ø–æ–ª–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á—ë—Ç.

–î–ò–ê–õ–û–ì –° –ü–ê–¶–ò–ï–ù–¢–û–ú:
{conversation}

–ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –î–ê–ù–ù–´–ï –ò–ó –ë–ê–ó–´:
{context}

–°–û–ë–†–ê–ù–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
- –û—Å–Ω–æ–≤–Ω–∞—è –∂–∞–ª–æ–±–∞: {chief_complaint}
- –°–∏–º–ø—Ç–æ–º—ã: {symptoms}
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}

–ó–∞–ø–æ–ª–Ω–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–ú–ù–ï–ó –¥–ª—è –≤—Ä–∞—á–∞:

**ANAMNESIS MORBI (–ò—Å—Ç–æ—Ä–∏—è –±–æ–ª–µ–∑–Ω–∏):**
[–†–∞–∑–≤–µ—Ä–Ω—É—Ç–æ –æ–ø–∏—à–∏: –Ω–∞—á–∞–ª–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è, —Ç–µ—á–µ–Ω–∏–µ, —Ä–∞–∑–≤–∏—Ç–∏–µ —Å–∏–º–ø—Ç–æ–º–æ–≤]

**–ñ–ê–õ–û–ë–´ –ò –°–ò–ú–ü–¢–û–ú–´:**
[–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–ø—Ç–æ–º–∞]

**–î–ò–§–§–ï–†–ï–ù–¶–ò–ê–õ–¨–ù–´–ô –î–ò–ê–ì–ù–û–ó:**
[–ù–∞ –æ—Å–Ω–æ–≤–µ –∂–∞–ª–æ–±—ã –∏ —Å–∏–º–ø—Ç–æ–º–æ–≤ –≤—ã–¥–≤–∏–Ω–∏ 3-5 –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –¥–∏–∞–≥–Ω–æ–∑–æ–≤]

**–ü–õ–ê–ù –û–ë–°–õ–ï–î–û–í–ê–ù–ò–Ø:**
1. –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ (–û–ê–ö)
2. –ë–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏
3. [–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –ø–æ–∫–∞–∑–∞–Ω–∏—è–º]

**–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
[–û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–∞—Ü–∏–µ–Ω—Ç—É]

–û—Ç—á—ë—Ç:""")
        
        try:
            from langchain_core.runnables import RunnableConfig
            
            print(" ‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ (30-60 —Å–µ–∫—É–Ω–¥)...")
            response = self.llm.invoke(
                prompt.format(
                    conversation=conversation if conversation else "–î–∏–∞–ª–æ–≥ –Ω–µ –±—ã–ª –ø—Ä–æ–¥—É–∫—Ç–∏–≤–µ–Ω",
                    context=context or "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
                    chief_complaint=self.collected_info["chief_complaint"],
                    symptoms=", ".join(symptoms_list),
                    duration=self.collected_info["duration"] or "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                ),
                config=RunnableConfig(timeout=90),
            )
            return response.content
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            
            # Fallback –æ—Ç—á—ë—Ç
            return f"""
**ANAMNESIS MORBI:**
–ü–∞—Ü–∏–µ–Ω—Ç –æ–±—Ä–∞—Ç–∏–ª—Å—è —Å –∂–∞–ª–æ–±–æ–π –Ω–∞: {self.collected_info['chief_complaint']}
–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {self.collected_info['duration'] if self.collected_info['duration'] else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}

**–ñ–ê–õ–û–ë–´ –ò –°–ò–ú–ü–¢–û–ú–´:**
{chr(10).join(f"- {s.capitalize()}" for s in symptoms_list)}

**–î–ò–§–§–ï–†–ï–ù–¶–ò–ê–õ–¨–ù–´–ô –î–ò–ê–ì–ù–û–ó:**
–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ä—è–≤–ª–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–± –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å:
- –û—Å—Ç—Ä—ã–µ –∏–Ω—Ñ–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è
- –•—Ä–æ–Ω–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è  
- –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–ü–õ–ê–ù –û–ë–°–õ–ï–î–û–í–ê–ù–ò–Ø:**
1. –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ (–û–ê–ö)
2. –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ—á–∏ (–û–ê–ú)
3. –ë–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏
4. –£–ó–ò –ø–æ –ø–æ–∫–∞–∑–∞–Ω–∏—è–º
5. –ü–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —É–∑–∫–∏—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤

**–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
- –°–æ–±–ª—é–¥–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –ø–æ–∫–æ—è
- –û–±–∏–ª—å–Ω–æ–µ –ø–∏—Ç—å—ë
- –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
"""

    # ---------- –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é ----------

    def start_interview(self):
        print("\n" + "=" * 70)
        print("ü©∫ –ú–ï–î–ò–¶–ò–ù–°–ö–û–ï –ò–ù–¢–ï–†–í–¨–Æ")
        print("=" * 70)
        print("\n–ö–æ–º–∞–Ω–¥—ã: '—Å—Ç–æ–ø' ‚Äî –∑–∞–≤–µ—Ä—à–∏—Ç—å, 'exit' ‚Äî –≤—ã—Ö–æ–¥\n")

        greeting = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ß—Ç–æ –≤–∞—Å –±–µ—Å–ø–æ–∫–æ–∏—Ç?"
        print(f"ü§ñ: {greeting}\n")
        self.conversation_history.append({"role": "assistant", "content": greeting})

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∂–∞–ª–æ–±—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        complaint = self._get_valid_patient_answer()
        if complaint is None:
            return
        if complaint == "STOP":
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            return

        self.collected_info["chief_complaint"] = complaint
        self.conversation_history.append({"role": "user", "content": complaint})
        self._extract_info(complaint)

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∏–Ω—Ç–µ—Ä–≤—å—é
        while self._should_continue():
            try:
                question = self._generate_question()
                print(f"\nü§ñ: {question}\n")
                self.conversation_history.append(
                    {"role": "assistant", "content": question}
                )

                # –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–≤–æ–¥ –ø–∞—Ü–∏–µ–Ω—Ç–∞
                answer = self._get_valid_patient_answer()
                if answer is None:
                    break
                if answer == "STOP":
                    break

                self.conversation_history.append({"role": "user", "content": answer})
                self._extract_info(answer)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                break

        print("\n" + "=" * 70)
        print("üìã –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–Å–¢–ê...")
        print("=" * 70)

        try:
            report = self._generate_report()
            print("\n" + "=" * 70)
            print("üìÑ –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –û–¢–ß–Å–¢")
            print("=" * 70 + "\n")
            print(report)
            print("\n" + "=" * 70)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = self.script_dir / f"report_{timestamp}.txt"
            with open(report_file, "w", encoding="utf-8") as f:
                f.write("–ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –û–¢–ß–Å–¢\n")
                f.write(f"–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
                f.write("=" * 70 + "\n\n")
                f.write(report)

            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {report_file.name}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á—ë—Ç–∞: {e}")


if __name__ == "__main__":
    import sys

    rebuild = "--rebuild" in sys.argv
    try:
        bot = MedicalInterviewBot(rebuild_db=rebuild)
        bot.start_interview()
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()