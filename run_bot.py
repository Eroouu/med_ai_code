from pathlib import Path
import json
import shutil
from datetime import datetime
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

class MedicalInterviewBot:
    def __init__(self, rebuild_db: bool = False):
        self.script_dir = Path(__file__).parent
        self.data_dir = self.script_dir / "cleaned_dataset"
        self.db_dir = self.script_dir / "vector_db"
        
        self.conversation_history = []
        self.collected_info = {
            "chief_complaint": "",
            "symptoms": [],
            "duration": "",
            "additional_info": []
        }
        
        print("=" * 70)
        print("üè• –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ò–ù–¢–ï–†–í–¨–Æ–ï–† v2.0")
        print("=" * 70)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        if not self.data_dir.exists() or not list(self.data_dir.glob("*.json")):
            print(f"\n‚ùå –ü–∞–ø–∫–∞ {self.data_dir} –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            print("   –°–æ–∑–¥–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–º–æ—â—å—é create_clean_dataset.py")
            exit(1)
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—É—é –±–∞–∑—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if rebuild_db and self.db_dir.exists():
            print("\nüóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
            try:
                shutil.rmtree(self.db_dir)
                print("   ‚úÖ –°—Ç–∞—Ä–∞—è –±–∞–∑–∞ —É–¥–∞–ª–µ–Ω–∞")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –±–∞–∑—É
        self._load_or_create_knowledge_base()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
        print("\nü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        self.llm = ChatOllama(model="llama3.2", temperature=0.3)
        print("   ‚úÖ –ì–æ—Ç–æ–≤–∞")
        
        print("\n" + "=" * 70)
        print("‚úÖ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê!")
        print("=" * 70)
    
    def _load_or_create_knowledge_base(self):
        """–£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π"""
        
        embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –±–∞–∑–∞
        db_exists = self.db_dir.exists() and any(self.db_dir.iterdir())
        
        if db_exists:
            print("\nüìö –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞")
            print(f"   –ü—É—Ç—å: {self.db_dir}")
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É
                self.vectorstore = Chroma(
                    persist_directory=str(self.db_dir),
                    embedding_function=embeddings
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –±–∞–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç
                test_results = self.vectorstore.similarity_search("—Ç–µ—Å—Ç", k=1)
                
                print("   ‚úÖ –ë–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                print(f"   üìä –°–æ–¥–µ—Ä–∂–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã: {len(test_results) > 0}")
                return
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã: {e}")
                print("   üîÑ –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
                
                # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—É—é –±–∞–∑—É
                try:
                    shutil.rmtree(self.db_dir)
                except:
                    pass
        
        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –±–∞–∑—É
        print("\nüìö –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")
        print("   ‚è≥ –≠—Ç–æ –∑–∞–π–º—ë—Ç 2-5 –º–∏–Ω—É—Ç (–¥–µ–ª–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)\n")
        
        self._create_new_database(embeddings)
    
    def _create_new_database(self, embeddings):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã —Å –Ω—É–ª—è"""
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print("1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        documents = []
        json_files = list(self.data_dir.glob("*.json"))
        
        if not json_files:
            print("   ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤ –≤ cleaned_dataset/")
            exit(1)
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(json_files)}")
        
        for i, json_file in enumerate(json_files, 1):
            try:
                with open(json_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                
                title = data.get("title", "")
                
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–µ–∫—Ü–∏–π
                full_text = f"# {title}\n\n"
                
                if "sections" in data:
                    for section_name, section_text in data["sections"].items():
                        if section_text and str(section_text).strip():
                            readable_name = section_name.replace("_", " ").title()
                            full_text += f"## {readable_name}\n{section_text}\n\n"
                
                if full_text.strip() and len(full_text) > 100:
                    doc = Document(
                        page_content=full_text,
                        metadata={
                            "title": title,
                            "disease": title,
                            "source": json_file.name
                        }
                    )
                    documents.append(doc)
                    
                    if i % 10 == 0:
                        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(json_files)}")
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ {json_file.name}: {e}")
        
        if not documents:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã!")
            exit(1)
        
        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π: {len(documents)}")
        
        # 2. –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏
        print("\n2Ô∏è‚É£ –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1200,
            chunk_overlap=150,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        splits = text_splitter.split_documents(documents)
        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(splits)}")
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
        print("\n3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...")
        print("   ‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
        
        try:
            # –°–æ–∑–¥–∞—ë–º –±–∞–∑—É –ø–æ—Ä—Ü–∏—è–º–∏ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
            batch_size = 50
            self.db_dir.mkdir(exist_ok=True)
            
            for i in range(0, len(splits), batch_size):
                batch = splits[i:i+batch_size]
                
                if i == 0:
                    # –ü–µ—Ä–≤–∞—è –ø–æ—Ä—Ü–∏—è - —Å–æ–∑–¥–∞—ë–º –±–∞–∑—É
                    self.vectorstore = Chroma.from_documents(
                        documents=batch,
                        embedding=embeddings,
                        persist_directory=str(self.db_dir)
                    )
                else:
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ—Ä—Ü–∏–∏ - –¥–æ–±–∞–≤–ª—è–µ–º
                    self.vectorstore.add_documents(batch)
                
                progress = min(i + batch_size, len(splits))
                print(f"   üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress}/{len(splits)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            
            print("\n   ‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
            print(f"   üìÅ –ü—É—Ç—å: {self.db_dir}")
            
        except Exception as e:
            print(f"\n   ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã: {e}")
            
            # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—É—é –±–∞–∑—É
            if self.db_dir.exists():
                try:
                    shutil.rmtree(self.db_dir)
                except:
                    pass
            
            raise
    
    def _search_context(self, query: str, k: int = 3) -> str:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            context = "\n\n".join([doc.page_content[:700] for doc in docs])
            return context
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return ""
    
    def _generate_question(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ë–î
        search_query = f"{self.collected_info['chief_complaint']} {' '.join(self.collected_info['symptoms'])}"
        context = self._search_context(search_query, k=2)
        
        # –ò—Å—Ç–æ—Ä–∏—è
        history = "\n".join([
            f"{'–í—Ä–∞—á' if msg['role'] == 'assistant' else '–ü–∞—Ü–∏–µ–Ω—Ç'}: {msg['content']}"
            for msg in self.conversation_history[-4:]
        ])
        
        prompt = ChatPromptTemplate.from_template("""
–¢—ã –≤—Ä–∞—á, —Å–æ–±–∏—Ä–∞—é—â–∏–π –∞–Ω–∞–º–Ω–µ–∑ —É –ø–∞—Ü–∏–µ–Ω—Ç–∞.

–ò–°–¢–û–†–ò–Ø –†–ê–ó–ì–û–í–û–†–ê:
{history}

–°–û–ë–†–ê–ù–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
- –ñ–∞–ª–æ–±–∞: {chief_complaint}
- –°–∏–º–ø—Ç–æ–º—ã: {symptoms}
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}

–ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
{context}

–ó–∞–¥–∞–π –û–î–ò–ù –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è:
1. –•–∞—Ä–∞–∫—Ç–µ—Ä —Å–∏–º–ø—Ç–æ–º–æ–≤ (–æ—Å—Ç—Ä–∞—è/—Ç—É–ø–∞—è –±–æ–ª—å, –≥–¥–µ –∏–º–µ–Ω–Ω–æ)
2. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –¥–∏–Ω–∞–º–∏–∫–∞
3. –°–≤—è–∑–∞–Ω–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã –∏–∑ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
4. –ü—Ä–æ–≤–æ—Ü–∏—Ä—É—é—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã

–í–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º –ø–∞—Ü–∏–µ–Ω—Ç—É.

–í–æ–ø—Ä–æ—Å:""")
        
        try:
            response = self.llm.invoke(prompt.format(
                history=history,
                chief_complaint=self.collected_info["chief_complaint"] or "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                symptoms=", ".join(self.collected_info["symptoms"]) if self.collected_info["symptoms"] else "–Ω–µ—Ç",
                duration=self.collected_info["duration"] or "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                context=context if context else "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
            ))
            return response.content.strip()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            return "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –≤–∞—à–∏—Ö —Å–∏–º–ø—Ç–æ–º–∞—Ö?"
    
    def _extract_info(self, text: str):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        text_lower = text.lower()
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        time_words = ['–¥–µ–Ω—å', '–¥–Ω—è', '–¥–Ω–µ–π', '–Ω–µ–¥–µ–ª—é', '–Ω–µ–¥–µ–ª–∏', '–º–µ—Å—è—Ü', '–≥–æ–¥']
        if any(w in text_lower for w in time_words) and not self.collected_info["duration"]:
            self.collected_info["duration"] = text
        
        # –°–∏–º–ø—Ç–æ–º—ã
        symptoms = ['–±–æ–ª—å', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–∂–∞—Ä', '—Ç–æ—à–Ω–æ—Ç–∞', '—Ä–≤–æ—Ç–∞', '—Å–ª–∞–±–æ—Å—Ç—å',
                   '–≥–æ–ª–æ–≤–Ω–∞—è', '–∫–∞—à–µ–ª—å', '–æ–¥—ã—à–∫–∞', '–¥–∏–∞—Ä–µ—è', '–∑–∞–ø–æ—Ä', '–∑—É–¥', '–æ—Ç–µ–∫']
        
        for symptom in symptoms:
            if symptom in text_lower:
                if symptom not in " ".join(self.collected_info["symptoms"]).lower():
                    self.collected_info["symptoms"].append(symptom)
    
    def _should_continue(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å"""
        questions = len([m for m in self.conversation_history if m["role"] == "assistant"])
        
        has_info = (
            bool(self.collected_info["chief_complaint"]) and
            (len(self.collected_info["symptoms"]) >= 2 or bool(self.collected_info["duration"]))
        )
        
        return questions < 8 and not has_info
    
    def _generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞"""
        
        search_query = " ".join([
            self.collected_info["chief_complaint"],
            *self.collected_info["symptoms"]
        ])
        context = self._search_context(search_query, k=5)
        
        conversation = "\n".join([
            f"{'–í—Ä–∞—á' if m['role'] == 'assistant' else '–ü–∞—Ü–∏–µ–Ω—Ç'}: {m['content']}"
            for m in self.conversation_history
        ])
        
        prompt = ChatPromptTemplate.from_template("""
–°–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á—ë—Ç –¥–ª—è –≤—Ä–∞—á–∞.

–ë–ï–°–ï–î–ê –° –ü–ê–¶–ò–ï–ù–¢–û–ú:
{conversation}

–ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
{context}

–§–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞:

**Anamnesis morbi:**
[–ò—Å—Ç–æ—Ä–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è: –∂–∞–ª–æ–±—ã, —Ö–∞—Ä–∞–∫—Ç–µ—Ä, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å]

**Anamnesis vitae:**
[–ê–Ω–∞–º–Ω–µ–∑ –∂–∏–∑–Ω–∏, –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–ª—Å—è]

**Clinical data:**
[–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ]

**Differential diagnosis:**
[–í–æ–∑–º–æ–∂–Ω—ã–µ –¥–∏–∞–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π]

**Recommendations:**
[–ü–ª–∞–Ω –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —Ç–∞–∫—Ç–∏–∫–∞]

–û—Ç—á—ë—Ç:""")
        
        try:
            response = self.llm.invoke(prompt.format(
                conversation=conversation,
                context=context if context else "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"
            ))
            return response.content
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞: {e}")
            return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞"
    
    def start_interview(self):
        """–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é"""
        print("\n" + "=" * 70)
        print("ü©∫ –ù–ê–ß–ê–õ–û –ú–ï–î–ò–¶–ò–ù–°–ö–û–ì–û –ò–ù–¢–ï–†–í–¨–Æ")
        print("=" * 70)
        print("\n–ö–æ–º–∞–Ω–¥—ã: '—Å—Ç–æ–ø' - –∑–∞–≤–µ—Ä—à–∏—Ç—å, 'exit' - –≤—ã—Ö–æ–¥\n")
        
        # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
        greeting = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤–∞—Å –±–µ—Å–ø–æ–∫–æ–∏—Ç?"
        print(f"ü§ñ: {greeting}\n")
        self.conversation_history.append({"role": "assistant", "content": greeting})
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∂–∞–ª–æ–±–∞
        complaint = input("üë§: ").strip()
        
        if complaint.lower() in ['exit', '–≤—ã—Ö–æ–¥']:
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            return
        
        if not complaint or complaint.lower() == '—Å—Ç–æ–ø':
            print("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –≤–∞—à—É –∂–∞–ª–æ–±—É")
            return
        
        self.collected_info["chief_complaint"] = complaint
        self.conversation_history.append({"role": "user", "content": complaint})
        self._extract_info(complaint)
        
        # –¶–∏–∫–ª –≤–æ–ø—Ä–æ—Å–æ–≤
        while self._should_continue():
            try:
                question = self._generate_question()
                print(f"\nü§ñ: {question}\n")
                self.conversation_history.append({"role": "assistant", "content": question})
                
                answer = input("üë§: ").strip()
                
                if answer.lower() in ['exit', '–≤—ã—Ö–æ–¥']:
                    print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    return
                
                if answer.lower() == '—Å—Ç–æ–ø':
                    break
                
                if not answer:
                    continue
                
                self.conversation_history.append({"role": "user", "content": answer})
                self._extract_info(answer)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                break
        
        # –û—Ç—á—ë—Ç
        print("\n" + "=" * 70)
        print("üìã –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–Å–¢–ê...")
        print("=" * 70)
        
        try:
            report = self._generate_report()
            
            print("\n" + "=" * 70)
            print("üìÑ –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –û–¢–ß–Å–¢")
            print("=" * 70 + "\n")
            print(report)
            print("\n" + "=" * 70)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = self.script_dir / f"report_{timestamp}.txt"
            
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(f"–ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –û–¢–ß–Å–¢\n")
                f.write(f"–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
                f.write("=" * 70 + "\n\n")
                f.write(report)
            
            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {report_file.name}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞: {e}")

if __name__ == "__main__":
    import sys
    
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–ª–∞–≥–∞ --rebuild
    rebuild = "--rebuild" in sys.argv or "-r" in sys.argv
    
    try:
        bot = MedicalInterviewBot(rebuild_db=rebuild)
        bot.start_interview()
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
