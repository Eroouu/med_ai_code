from pathlib import Path
import json
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

script_dir = Path(__file__).parent
data_dir = script_dir / "cleaned_dataset"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –û–ß–ò–©–ï–ù–ù–´–ï –¥–∞–Ω–Ω—ã–µ!
db_dir = script_dir / "chroma_db_optimized"

db_dir.mkdir(exist_ok=True)

try:
    print("=" * 70)
    print("üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô RAG-–°–ò–°–¢–ï–ú–´")
    print("=" * 70)

    print("\n1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    documents = []
    json_files = list(data_dir.glob("**/*.json"))

    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(json_files)} —Ñ–∞–π–ª–æ–≤")

    for json_file in json_files:
        try:
            with open(json_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            full_text = data.get("title", "") + "\n\n"

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ä–∞–∑–¥–µ–ª–æ–≤
            if "sections" in data:
                for section_name, section_data in data["sections"].items():
                    if isinstance(section_data, dict) and "text" in section_data:
                        full_text += f"## {section_name}\n{section_data['text']}\n\n"

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if "applications" in data:
                for app_name, app_data in data["applications"].items():
                    if app_data.get("type") == "tables":
                        full_text += f"### {app_name} (—Ç–∞–±–ª–∏—Ü–∞)\n"
                        for table in app_data.get("tables", []):
                            for row in table:
                                full_text += (
                                    " | ".join(str(cell) for cell in row) + "\n"
                                )
                            full_text += "\n"

            if full_text.strip():
                doc = Document(
                    page_content=full_text, metadata={"source": json_file.name}
                )
                documents.append(doc)
                print(f"   ‚úÖ {json_file.name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  {json_file.name}: {e}")

    print(f"\n   –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    if len(documents) == 0:
        print("   ‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ cleaned_dataset/")
        exit(1)

    print("\n2Ô∏è‚É£ –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û)...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000, chunk_overlap=200  # –ë–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞ = –º–µ–Ω—å—à–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    )
    splits = text_splitter.split_documents(documents)
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(splits)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (–≤–º–µ—Å—Ç–æ 1.6 –º–ª–Ω!)")

    print("\n3Ô∏è‚É£ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    embeddings = OllamaEmbeddings(model="nomic-embed-text")
    print("   ‚úÖ –ì–æ—Ç–æ–≤–æ")

    print("\n4Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã (–±—ã—Å—Ç—Ä–æ!)...")
    vectorstore = Chroma.from_documents(
        documents=splits, embedding=embeddings, persist_directory=str(db_dir)
    )
    print("   ‚úÖ ChromaDB —Å–æ–∑–¥–∞–Ω–∞")

    print("\n5Ô∏è‚É£ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM...")
    llm = ChatOllama(model="llama3.1:8b", temperature=0)
    print("   ‚úÖ –ì–æ—Ç–æ–≤–∞")

    print("\n" + "=" * 70)
    print("‚ú® –ß–ê–¢-–ë–û–¢ –ì–û–¢–û–í ‚ú®")
    print("=" * 70 + "\n")

    while True:
        question = input("‚ùì –í–æ–ø—Ä–æ—Å: ").strip()

        if question.lower() in ["–≤—ã—Ö–æ–¥", "exit", "quit"]:
            print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break

        if not question:
            continue

        print("\n‚è≥ –ê–Ω–∞–ª–∏–∑...\n")

        try:
            docs = vectorstore.similarity_search(question, k=5)
            context = "\n---\n".join([doc.page_content for doc in docs])

            prompt = ChatPromptTemplate.from_template(
                """–í—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.

–î–û–ö–£–ú–ï–ù–¢–´:
{context}

–í–û–ü–†–û–°: {question}

–û–¢–í–ï–¢:"""
            )

            chain = prompt | llm
            response = chain.invoke({"context": context, "question": question})

            print(f"üìù {response.content}\n")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}\n")

except Exception as e:
    print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}\n")
    import traceback

    traceback.print_exc()
